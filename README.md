# -Google-Data-Analytics-Bellabeat-Case-Study
- Author: Nadia Sharief
- Date:  feb 1, 2023

**Introduction**


This is a Capstone Project for the Google Data Analytics Professional Certification.

Bellabeat is a high-tech company that manufactures health-focused smart products that help women easily track their overall health and wellness, and get connected to their body and mind throughout different stages in life.

The case study follows the six step data analysis process:

â“ Ask
ðŸ’» Prepare
ðŸ›  Process
ðŸ“Š Analyze
ðŸ“‹ Share
ðŸ§—â€â™€ï¸ Act

## Phase 1: Ask


**1. Identify the business task:**

- Analyse smart devices usage data
- Provide high quality recommendations for Bellabeatâ€™s marketing strategy

**Questions to guide analysis:**

- What are some of the trends in smart device usage?
- How can you apply these trends to Bellabeat customers?
- How can these trends help influence Bellabeat marketing strategy?

**2. Consider key stakeholders**

Primary Stakeholder(s):

- Urska Srsen - Chief Executive Officer (CEO) and co-founder of Bellabeat
- Sando Mur - Mathematician and co-founder of Bellabeat

Secondary Stakeholder:

- Bellabeat Marketing Analytics Team

**Phase 2: Prepare**

Data Source: 30 participants FitBit Fitness Tracker Data from Mobius: https://www.kaggle.com/arashnic/fitbit

The dataset has 18 CSV. The data also follow a ROCCC approach:

- Reliability: The data is from 30 FitBit users who consented to the submission of personal tracker data and generated by from a distributed survey via Amazon Mechanical Turk.

- Original: The data is from 30 FitBit users who consented to the submission of personal tracker data via Amazon Mechanical Turk.

- Comprehensive: Data minute-level output for physical activity, heart rate, and sleep monitoring. While the data tracks many factors in the user activity and sleep,   but the sample size is small and most data is recorded during certain days of the week.

- Current: Data is from March 2016 to May 2016. Data is not current so the users habit may be different now.

- Cited: Unknown.

**The dataset has limitations:**

- Only 30 user data is available. The central limit theorem general rule of nâ‰¥30 applies and we can use the t test for statstic reference. However, a larger sample    size is preferred for the analysis.

- Upon further investigation with unique() to check for unique user Id, the set has 33 user data from daily activity, 24 from sleep and only 8 from weight. There are 3 extra users and some users did not record their data for tracking daily activity and sleep.

- For the 8 user data for weight, 5 users manually entered their weight and 3 recorded via a connected wifi device (eg: wifi scale).

- Most data is recorded from Tuesday to Thursday, which may not be comprehensive enough to form an accurate analysis.


## Phase 3: PROCESS

### Preparing the Environment
```
#Importing python packages

import numpy as np # data arrays
import pandas as pd # data structures and analysis
import matplotlib as plt # data visualisation
import datetime as dt # date and time
```
### Importing 4 datasets
```
# daily_activity  -  read_csv function to read the required CSV file

daily_activity = pd.read_csv(r"C:\Users\nadia\OneDrive\Desktop\Fitabase Data 4.12.16-5.12.16\dailyActivity_merged.csv")
```

```
# sleep_day  -  read_csv function to read the required CSV file

sleep_day = pd.read_csv(r"C:\Users\nadia\OneDrive\Desktop\Fitabase Data 4.12.16-5.12.16\sleepDay_merged.csv")
```

```
# weight - read_csv function to read the required CSV file

weight = pd.read_csv(r"C:\Users\nadia\OneDrive\Desktop\Fitabase Data 4.12.16-5.12.16\weightLogInfo_merged.csv")
```

```
hourly_steps = pd.read_csv(r"C:\Users\nadia\OneDrive\Desktop\Fitabase Data 4.12.16-5.12.16\hourlySteps_merged.csv")
```

### Data Cleaning & Manipulation 

**Steps**

- Observe and familiarize with data

- Check for null or missing values

- Perform sanity check of data

- Previewing using head function to show the first 10 rows of daily_activity to familiarise with the data.

**1. Data Frame - daily_activity**

```
#obtain the # of missing data points per column

null_values_count = daily_activity.isnull().sum()


#checking for duplicates 

duplicates = daily_activity.duplicated().sum()

print('Number of duplicates: ' + str(duplicates))


#to check the data types of columns

daily_activity.dtypes


#To get the info of the data frame

daily_activity.info()


#number of rows and columns 
daily_activity.shape


unique_id =len(pd.unique(daily_activity['Id']))

print(" Number of unique id: "  + str(unique_id))
```

From the above observation, noted that

1.  There is no typo, Null or missing values.

2.  Data frame has 940 rows and 15 columns.

3.  ActivityDate is wrongly classified as object dtype and has to be converted to datetime64 dtype.

4.  There are 33 unique IDs, instead of 30 unique IDs as expected from 30 fitness tracker users.

The following data manipulation has to be performed:

1. Convert the *ActivityDate* to datetime64 dtype.

2. Convert format of *ActivityDate* to yyyy-mm-dd

3. Create new column *DayOfTheWeek* by seperating the date into day of the week for further analysis

4. Create new column *TotalMins* being the sum of *VeryActiveMinutes*, *FairlyActiveMinutes*,
   *LightlyActiveMinutes* and *SedentaryMinutes*

5. Create new column *TotalHours* by converting new column in *TotalMins* to *NumberOfHours*

6. Rearrange and rename columns.

```

#Convert the ActivityDate to datetime64 dtype.

daily_activity["ActivityDate"] = pd.to_datetime(daily_activity["ActivityDate"], format="%m/%d/%Y")



# create new list of rearranged columns

new_cols = ['Id', 'ActivityDate','DayOfWeek' , 'TotalSteps', 'TotalDistance', 'TrackerDistance',
       'LoggedActivitiesDistance', 'VeryActiveDistance',
       'ModeratelyActiveDistance', 'LightActiveDistance',
       'SedentaryActiveDistance', 'VeryActiveMinutes', 'FairlyActiveMinutes',
       'LightlyActiveMinutes', 'SedentaryMinutes','TotalExerciseMinutes','TotalExerciseHours', 'Calories']

#  reindex function to rearrange columns based on "new_cols"

df_activity = daily_activity.reindex(columns = new_cols) 


#Creating new column by converting total_mins to number of hours
# create new column "day_of_the_week" to represent day of the week 

df_activity['DayOfWeek']=df_activity['ActivityDate'].dt.day_name()



#Rearranging and renaming columns from XxxYyy to xxx_yyy.

df_activity = df_activity.rename(columns ={"Id":"id","ActivityDate":"date","DayOfWeek":"day_of_the_Week","TotalSteps":"total_steps","TotalDistance":"total_dist","TrackerDistance":"tracker_dist","LoggedActivitiesDistance":"logged_activities_dist","VeryActiveDistance":"very_active_dist","ModeratelyActiveDistance":"moderately_active_dist","LightActiveDistance":"light_active_dist","SedentaryActiveDistance":"sedentary_active_dist","VeryActiveMinutes":"very_active_mins","FairlyActiveMinutes":"fairly_active_mins","LightlyActiveMinutes":"lightly_active_mins","SedentaryMinutes":"sedentary_mins","TotalExerciseMinutes":"total_mins","TotalExerciseHours":"total_hours","Calories":"calories"})

# print column names to confirm
print(df_activity.columns.values)
df_activity.head(5)




# create new column "total_mins" containing sum of total minutes.

df_activity['total_mins'] = df_activity['very_active_mins'] + df_activity['fairly_active_mins'] + df_activity['lightly_active_mins'] +  df_activity['sedentary_mins']


#Creating new column by converting total_mins to number of hours

# inserting data into total hours by calculating 

df_activity['total_hours']= round(df_activity['total_mins'] / 60)
```

**2. Data Frame - sleep_day**

```
# Checking if there are duplicates in this data frame

sleep_day.duplicated().sum()

print("Number of duplicates: " + str(sleep_day.duplicated().sum()))

# Duplicates dropped

sleep_day = sleep_day.drop_duplicates()



# Checking for null records

null_values_count =  sleep_day.isnull().sum()

# Checking the number of null records in the data frame's columns 

null_values_count[:]


# information of data frame

sleep_day.info()


# shape of data frame

sleep_day.shape


#data types 

sleep_day.dtypes


# To check the number of unique records

sleep_day.nunique()
``` 

From the above observation, noted that

- There were duplicates, Null or missing values which has been dropped and removed 

- Data frame has 410 rows and 5 columns.

- SleepDay is wrongly classified as object dtype and has to be converted to datetime64 dtype.

- There are 24 unique IDs, instead of 30 unique IDs as expected from 30 fitness tracker users.

The following data manipulation has to be performed:

- Convert the SleepDay to datetime64 dtype.

- Convert format of SleepDay to yyyy-mm-dd.

- Create new column DayOfTheWeek by seperating the date into day of the week for further analysis

- Rearrange and rename columns.

```
# Converting the SleepDay column data type 'O' to datetime

sleep_day['SleepDay'] = pd.to_datetime(sleep_day['SleepDay'] )


#Converting the date into day of week column 

sleep_day['day_of_the_week'] = sleep_day['SleepDay'].dt.day_name()

sleep_day[:]


# Rearranging the columns 

new_cols = ['Id', 'SleepDay','day_of_the_week','TotalSleepRecords' , 'TotalMinutesAsleep', 'TotalTimeInBed']


#  reindex function to rearrange columns based on "new_cols"

sleep_day = sleep_day.reindex(columns = new_cols) 


#Renaming the columns

sleep_day = sleep_day.rename(columns ={"Id":"id","SleepDay":"date","day_of_the_week":"day_of_the_Week","TotalSleepRecords":"total_sleep_records","TotalMinutesAsleep":"total_mins_asleep","TotalTimeInBed":"total_time_inbed"})

# print column names to confirm
print(sleep_day.columns.values)
sleep_day.head(5)


#creating a column for awake time

sleep_day['awake_time'] = sleep_day['total_time_inbed'] - sleep_day['total_mins_asleep']
```


**3. Data Frame - Weight**
```
# checking for null values

null_values = weight.isnull().sum()
```

We will leave the NA. The NA belong to "Fat" data of different dates.

```
null_values[:]

# checking for duplicates

weight.duplicated().sum()

# number of rows and columns

weight.shape

# deriving information

weight.info()

# To derive the unique records
weight.nunique()
```

From the above observation, noted that

- There were no duplicates, Null or missing values will be ignored because of the vast number of other data that could 
   be of use for further analysis 
   
- Data frame has 67 rows and 8 columns.

- Date is wrongly classified as object dtype and has to be converted to datetime64 dtype.

- There are 8 unique IDs, instead of 30 unique IDs as expected from 30 fitness tracker users.

- Day of the week column should be created from Date column

The following data manipulation has to be performed:

- Convert the Date to datetime64 dtype.

- Convert format of Date to yyyy-mm-dd.

- Create new column DayOfTheWeek by seperating the date into day of the week for further analysis

- Rearrange and rename columns.

- After the Time column is created . Remove the time series from the Date column


```
#Converting dtype 'O' to 'datetime64'

weight['Date'] = pd.to_datetime(weight['Date'] )

weight['Date'] = pd.to_datetime(weight['Date'], format ="%m/%d/%Y")


# To check the data types
weight.dtypes


# creating a colum for day of the week

weight['day_of_the_week'] = weight['Date'].dt.day_name()

weight[:]


#Creating a time column from the Date column

weight['time'] = weight['Date'].dt.time


# Removing the time stamp from the 'Date' column 

weight['Date'] = weight['Date'].dt.date

# Rearranging the columns 

new_cols = ['Id', 'Date','day_of_the_week','WeightKg' , 'WeightPounds', 'Fat', 'BMI','IsManualReport','LogId','time']

#  reindex function to rearrange columns based on "new_cols"
weight = weight.reindex(columns = new_cols) 



#Renaming the columns

weight = weight.rename(columns ={"Id":"id","Date":"date","day_of_the_week":"day_of_the_Week","WeightKg":"weight_kg","WeightPounds":"weight_pounds","Fat":"fat","BMI":"bmi","IsManualReport":"is_manual_report","LogId":"log_id",'time':"time"})

# print column names to confirm
print(weight.columns.values)
weight.head(5)
```


### **3. Data Frame - Hourly Steps**

```
# checking the data types

hourly_steps.dtypes

# Rearranging the columns 

new_cols = ['Id', 'ActivityHour','StepTotal','hour' ]

#  reindex function to rearrange columns based on "new_cols"

hourly_steps = hourly_steps.reindex(columns = new_cols) 

# Converting the data types 

hourly_steps['ActivityHour'] = pd.to_datetime(hourly_steps['ActivityHour'])

hourly_steps['ActivityHour'] = pd.to_datetime(hourly_steps['ActivityHour'],format = '%d/%m/%y %H:%M:%S')


# inserting hour values using dt.hour

hourly_steps['hour'] = hourly_steps['ActivityHour'].dt.hour
```



From the above observation, noted that

- There were no duplicates, Null or missing values 

- Date is wrongly classified as object dtype and has to be converted to datetime64 dtype.

- Create a column to seperate the %H to a column called Hour

The following data manipulation has to be performed:

- Convert the Date to datetime64 dtype.

- Convert format of Date to yyyy-mm-dd %H : %M : %S.

- Rearrange and rename columns.

### Merging 3 dataframes into one single data frame 


```
merged1 = pd.merge(df_activity, sleep_day, on= 'id')

merged_data = pd.merge(merged1, weight, on ='id')
```






## Phase 4: ANALYZE

-   count - no. of rows
-   mean (average)
-   std (standard deviation)
-   min and max
-   percentiles 25%, 50%, 75%

### 1. Analytical findings - General Statistics

```
# pull general statistics 

df_activity.describe()
```
**Interpreting statistical findings:**

1.  On average, users logged 7,637 steps or 5.4km which is not adequate. As recommended by CDC, an adult female has to aim at       least 10,000 steps or 8km per day to benefit from general health, weight loss and fitness improvement. Source: Medical News Today article

2.  Sedentary users are the majority logging on average 991 minutes or 20 hours making up 81% of total average minutes.

3.  Noting that average calories burned is 2,303 calories equivalent to 0.6 pound. Could not interpret into detail as calories       burned depend on several factors such as the age, weight, daily tasks, exercise, hormones and daily calorie intake. Source:  Health Line article

### 2. Analytical findings - General Statistics on the Merged Data

```
merged_data.describe()
```

**Interpreting statistical findings:**

-  Avg weight is 139 pounds with BMI of 24 and burn 2011 calories.


-  Avg steps is 9656, max is almost triple that 20031 steps. 


-  Users spend on avg 12 hours a day in sedentary minutes, 4 hours lightly active, only half hour in fairly+very active!


-   Users also gets about 7 hour of sleep.

### 3. Analytical Findings - Sleep patterns 

```
sleep_day.describe()
```
**Interpreting statistical findings:**


- Participants spent, on average, 458.6 minutes (7.64 hours) in bed.


- Average sleeping time was 419.5 minutes or 7 hours.


- Participants slept once per day on average.

### 4. Analytical Findings - Number of users that are active 

**Analysis on active minutes, calorie, total steps.**

- The **American Heart Association** and **World Health Organization** recommend at least 150 minutes of moderate-intensity
  activity or 75 minutes of vigorous activity, or a combination of both, each week. 
- That means it needs an daily goal 
  of 21.4 minutes of FairlyActiveMinutes or 10.7 minutes of VeryActiveMinutes
  
  
- In our dataset, **30 users** met fairly active minutes or very active minutes.

```
active_mins = df_activity[(df_activity['fairly_active_mins'] >= 21) | 
                          (df_activity['very_active_mins'] >= 11)].groupby('id').count()
```

In our dataset, **30 users** met fairly active minutes or very active minutes.

## 5. Analytical Findings - Calculated the percentages of various minutes
```
# percentage of sedentary percentage

sedentary_percentage = (df_activity['sedentary_mins'].sum() / df_activity['total_mins'].sum()*100)

```
Result: 81.32989068004622

```
# percentage of lightly_percentage

lightly_percentage = (df_activity['lightly_active_mins'].sum() / df_activity['total_mins'].sum()*100)

```
Result : 15.820493214202166

```
# percentage of Fairly_percentage

fairly_percentage = (df_activity['fairly_active_mins'].sum() / df_activity['total_mins'].sum() * 100)
```
Result: 1.1130139975629088

```
# percentage of Active_percentage

active_percentage = (df_activity['very_active_mins'].sum() / df_activity['total_mins'].sum() * 100)
```
Result: 1.7366021081886964

created a new data frame and inserted the two columns into it for the purpose of pie chart
```
data = {'level': ['Sedentary', 'Lightly', 'Fairly', 'Very Active'],
        'Minutes': [sedentary_percentage, lightly_percentage, fairly_percentage, active_percentage]}
        
df = pd.DataFrame(data)
```
----------
Check to see if we have 30 users using nunique(). The dataset has 33 user data from daily activity, 
24 from sleep and only 8 from weight. If there is a discrepency such as in the weight table, check to see how
the data are recorded. The way the user record the data may give you insight on why there is missing data.
```
weight[weight['is_manual_report'] != 'False'].groupby(id).sum().nunique()
```

### 6. Analytical findings - Number of users who's awake time exceeded 55 minutes
```
awake_time = sleep_day[sleep_day['awake_time'] >= 55].groupby('id').size().sort_values( ascending = False)

awake_time.nunique()
```
Result: 6

**Analysis** 

- According to article: https://blog.fitbit.com/sleep-    study/#:~:text=The%20average%20Fitbit%20user%20is,is%20spent%20restless%20or%20awake.&text=People%20who%20sleep%205%20hours,the%20beginning%20of%20the%20night. 


- 55 minutes are spend awake in bed before going to sleep. Let see how many users in our study is according to the FitBit data


## 7. Analytical Findigs - identifying Users that are Under weight, Healthy weight, Over weight or Obese using BMI

- **If your BMI is less than 18.5, it falls within the underweight range.**
- **If your BMI is 18.5 to 24.9, it falls within the Healthy Weight range.**
- **If your BMI is 25.0 to 29.9, it falls within the overweight range.**
- **If your BMI is 30.0 or higher, it falls within the obese range.**

The American Heart Association and World Health Organization recommend at least 150 minutes of moderate-intensity activity or 75 minutes of vigorous activity, or a combination of both, each week.

That means it needs an daily goal of 21.4 minutes of FairlyActiveMinutes or 10.7 minutes of VeryActiveMinutes
 
**Underweight**
```

underweight = merged_data[merged_data['bmi'] < 18.5 ].groupby('id').count()
```
saving into csv 
```
underweight.to_csv('underweight_file.csv')
```
creating a df

```
df_underweight = pd.read_csv(r"C:\Users\nadia\Downloads\underweight_file.csv")
```
**Analysis**

There are no underweight user's

**Healthy Weight**

```

healthyweight = merged_data[merged_data['bmi'].between(18.5, 24.9)].groupby('id').count()
```
creating a csv 
```
healthyweight.to_csv('healthyweight_file.csv')
```
creating a df 
```
df_healthyweight = pd.read_csv(r"C:\Users\nadia\Downloads\healthyweight_file.csv")
```

To check how many healthy users actually exercise the required level

```
healthyweight_analysis = df_healthyweight[(df_healthyweight['fairly_active_mins'] >= 21) | 
                          (df_healthyweight['very_active_mins'] >= 11)].groupby('id').nunique()
```
**Analysis**

The 2 user that has been found as obese does exercise that's required for them to maintain a healthy lifestyle

**Over Weight**

```
overweight = merged_data[merged_data['bmi'].between(25.0, 29.0)].groupby('id').count()
```
creating a csv file
```
overweight.to_csv('overweight_file.csv')
```
creating a df
```
df_overweight = pd.read_csv(r"C:\Users\nadia\Downloads\overweight_file.csv")
```
To check how many healthy users actually exercise the required level
```
overweight_analysis = df_overweight[(df_overweight['fairly_active_mins'] >= 21) | 
                          (df_overweight['very_active_mins'] >= 11)].groupby('id').nunique()
```                          
**Analysis**

The one user that has been found as obese does exercise that's required. 


**Obese weight**
```
obeseweight = merged_data[merged_data['bmi'] > 30.0].groupby('id').count()
```
creating a csv file
```
obeseweight.to_csv('obeseweight_file.csv')
```
creating a df
```
df_obeseweight = pd.read_csv(r"C:\Users\nadia\Downloads\obeseweight_file.csv")
```
To check how many healthy users actually exercise the required level
```
obeseweight_analysis = df_obeseweight[(df_obeseweight['fairly_active_mins'] >= 21) | 
                          (df_obeseweight['very_active_mins'] >= 11)]
 ```                         
**Analysis**

The one user that has been found as obese does exercise that's required. 

## Phase 5: SHARE

Visualisations
Here, I will create visualisations to find relationships between the variables.

**Active Minutes:**

Percentage of active minutes in the four categories: very active, fairly active, lightly active and sedentary. From the pie chart, we can see that most users spent 81.3% of their daily activity in sedentary minutes and only 1.74% in very active minutes.

```
my_label = ['Sedentary', 'Lightly', 'Fairly', 'Very Active']

df.plot.pie(y='Minutes',figsize=(6,6),fontsize=12,legend = True, labels = my_label, counterclock = False,autopct = '%1.1f%%',
            pctdistance=1.1, labeldistance=1.2,title = 'Activity Level Minutes',ylabel = (" ") );          
```
![pie](https://user-images.githubusercontent.com/100290609/217098837-8eb32b77-df92-4873-b416-72df42eef5e9.png)

**Analysis**

As seen from the pie chart,

1. Sedentary minutes takes the biggest slice at 81.3%.

2. This indicates that users are using the FitBit app to log daily activities such as daily commute, inactive movements (moving from one spot to another) or running errands.

3. App is rarely being used to track fitness (ie. running) as per the minor percentage of fairly active activity (1.1%) and very active activity (1.7%). This is highly discouraging as FitBit app was developed to encourage fitness.

**Day Of Week VS Frequency of usage**

```
# import matplotlib package
import matplotlib.pyplot as plt
â€‹
# plotting histogram
plt.style.use("default")
plt.figure(figsize=(6,4)) # specify size of the chart
plt.hist(df_activity.day_of_the_Week, bins = 7, 
         width = 0.6, color = "lightblue", edgecolor = "black")
â€‹
# adding annotations and visuals
plt.xlabel("Day of the week")
plt.ylabel("Frequency")
plt.title("No. of times users logged in app across the week")
plt.grid(True)
plt.show()
â€‹
â€‹
```
![image](https://user-images.githubusercontent.com/100290609/217099109-2079f721-83c8-4255-b357-4c0532a20f05.png)

**Analysis**

**Frequency of usage across the week**


1.  In this histogram, we are looking at the frequency of FitBit app usage in terms of days of the week.


2.  We discovered that users prefer or remember (giving them the doubt of benefit that they forgotten) to track their activity       on the app during midweek from Tuesday to Friday.


3.  Noting that the frequency dropped on Friday and continue on weekends and Monday.

**Calories VS Total Steps Taken**

```
# plotting scatter plot
plt.style.use("default")
plt.figure(figsize=(8,6)) # specify size of the chart
plt.scatter(df_activity.total_steps, df_activity.calories, 
            alpha = 0.8, c = df_activity.calories, 
            cmap = "Spectral")
â€‹
mean_total_steps = 7638
mean_calories = 2303
â€‹
â€‹
plt.scatter(df_activity.total_steps,df_activity.calories,alpha = 0.9, c = df_activity.calories, 
            cmap = "Spectral")
plt.colorbar(orientation = "vertical")
plt.axvline(mean_total_steps, color = "Blue", label = "Mean steps")
plt.axhline(mean_calories, color = "Red", label = "Mean Calories")
plt.xlabel("Steps taken")
plt.ylabel("Calories Burned")
plt.title("Calories burned for every step taken")
plt.grid(True)
plt.legend()
plt.show()
```
![image](https://user-images.githubusercontent.com/100290609/217099499-4b3b9178-f921-40f6-8279-3b89467a93a0.png)


**Analysis**

**Calories burned for every step taken**

From the scatter plot, we discovered that:

1. Mean Calories = 2303
2. Mean Total steps = 7637
3. It is a positive correlation.
4. We observed that intensity of calories burned increase when users are at the range of > 0 to 15,000 steps with calories burn rate cooling down from 15,000 steps onwards.

Noted a few outliers:

1. Zero steps with zero to minimal calories burned.
2. 1 observation of > 35,000 steps with < 3,000 calories burned.
3. Deduced that outliers could be due to natural variation of data, change in user's usage or errors in data collection (ie. miscalculations, data contamination or human error).

**Hours Logged VS Calories burned**
```
# plotting scatter plot
plt.style.use("default")
plt.figure(figsize=(8,6)) # Specify size of the chart
plt.scatter(df_activity.total_hours, df_activity.calories, 
            alpha = 0.8, c = df_activity.calories, 
            cmap = "Spectral")
â€‹
# adding annotations and visuals
mean_calories = 2303
mean_hours = 20
mean_sedentary = 991 / 60
â€‹
plt.colorbar(orientation = "vertical")
plt.axvline(mean_hours, color = "Blue", label = "Mean steps")
plt.axvline(mean_sedentary, color = "Purple", label = "Mean sedentary")
plt.axhline(mean_calories, color = "Red", label = "Mean hours")
plt.xlabel("Hours logged")
plt.ylabel("Calories burned")
plt.title("Calories burned for every hour logged")
plt.legend()
plt.grid(True)
plt.show()
````
![image](https://user-images.githubusercontent.com/100290609/217099716-49c21277-1e0f-41e5-923f-49372e7733cf.png)

**Analysis**
â€‹
**Calories burned for every hour logged**
â€‹
The scatter plot is showing:
â€‹
1. A weak positive correlation whereby the increase of hours logged does not translate to more calories being burned. 
   That is largely due to the average sedentary hours (purple line) plotted at the 16 to 17 hours range.
â€‹
Again, we can see a few outliers:
â€‹
1. The same zero value outliers
2. An unusual red dot at the 24 hours with zero calorie burned which may be due to the same reasons as above.
â€‹


**Relationship between Total Steps and Sedentary Minutes**
```
# plotting scatter plot
plt.style.use("default")
plt.figure(figsize=(8,6)) # specify size of the chart
plt.scatter(merged_data.total_steps, merged_data.sedentary_mins, 
            alpha = 0.8, c = merged_data.sedentary_mins, 
            cmap = "Spectral")
â€‹
mean_total_steps = 7638
mean_calories = 991
â€‹
â€‹
plt.scatter(merged_data.total_steps,merged_data.sedentary_mins,alpha = 0.9, c = merged_data.sedentary_mins, 
            cmap = "Spectral")
plt.colorbar(orientation = "vertical")
plt.axvline(mean_total_steps, color = "Blue", label = "Mean steps")
plt.axhline(mean_calories, color = "Red", label = "Mean calories burned")
plt.xlabel("Steps taken")
plt.ylabel("Sedentary Minutes")
plt.title("Relationship between Total Steps and Sedentary Minutes")
plt.grid(True)
plt.legend()
plt.show()
```
![image](https://user-images.githubusercontent.com/100290609/217099872-d8b6b07e-8256-4d05-86fb-1c4410f3b1e6.png)

**Analysis**
â€‹
**Total steps and Sedentary minutes**
â€‹
1.  This graph shows a negative correlation between total steps and sedentary minutes 
2.   The lower the total steps, the higher the sedentary minutes.


**Less Sedentary Minutes on Saturday**
```
week_days = df_activity.groupby('day_of_the_Week',sort=False)
â€‹
sedentary_mins = week_days.sum()['sedentary_mins']
â€‹
days = [days for days, df in week_days]
â€‹
plt.bar(days,sedentary_mins)
plt.xticks(days,rotation = 'vertical',size = 8)
plt.xlabel('Week Days')
plt.ylabel('Sedentary Minutes')
plt.title("Less Sedentary Minutes on Saturday")
plt.show()
```
![image](https://user-images.githubusercontent.com/100290609/217100140-42902811-115d-4dd2-9485-ecfd710691c2.png)

**Analysis**

1. The bar graph shows that there is a jump on Saturday: user spent LESS time in sedentary minutes and took MORE steps.


**The Relationship Between Lightly Active Minutes and Calories Burned** 

```
from plotnine import *  # geom plots from R 
from plotnine.data import *

%matplotlib inline

(
    ggplot(df_activity, aes(x='lightly_active_mins', y='calories'))
    + geom_point()
    + geom_smooth(color="cyan", se= False)
    + labs(x='Lightly Active minutes', y='Calories')
     + theme(figure_size = (9, 5))
)
```
![image](https://user-images.githubusercontent.com/100290609/217100390-304dbac8-f542-4a93-ac59-b2dbc0e8e097.png)


**The Relationship Between Fairly Active Minutes and Calories Burned**
```
(
    ggplot(df_activity, aes(x='fairly_active_mins', y='calories'))
    + geom_point()
    + geom_smooth(color="cyan", se= False)
    + labs(x='fairly Active minutes', y='Calories')
     + theme(figure_size = (9, 5))
     
)
```
![image](https://user-images.githubusercontent.com/100290609/217100498-28984ffa-0221-496f-b2a2-5a196f26e29e.png)

**The Relationship Between Very Active Minutes and Calories Burned**
```
(
    ggplot(df_activity, aes(x='very_active_mins', y='calories'))
    + geom_point()
    + geom_smooth(color="cyan", se= False)
    + labs(x='Very Active minutes', y='Calories')
    + theme(figure_size = (9, 5))
    
)
```
![image](https://user-images.githubusercontent.com/100290609/217100605-b9305d60-58f5-4f92-b27b-20d4f58c0a47.png)

**Analysis**

- **The Relationship Between Lightly Active Minutes and Calories Burned**

- **The Relationship Between Fairly Active Minutes and Calories Burned**

- **The Relationship Between Very Active Minutes and Calories Burned**



From these graphs


1. we can clearly see that there are positive relationships between very active minutes, and lightly active minutesâ€™ against      the calories burned.


2. However, there seems to be a negative relationship between fairly active minutes and the number of calories burned.



3. We can also see that more calories were burned with people who did lighter activities compared to those who were very and/or    fairly active.

**Relationship between Total time asleep and Total time in bed**
```
(
    ggplot(sleep_day, aes(x='total_mins_asleep', y='total_time_inbed'))
    + geom_point()
    + geom_smooth(color="blue", se= False)
    + labs(x='Total Minutes Asleep', y='Total Time In Bed')
    + theme(figure_size = (9, 5))
    
)
```
![image](https://user-images.githubusercontent.com/100290609/217100813-e322d0ae-b9f9-4516-b202-187f42bd17cc.png)

**Analysis**

**Relationship between total time asleep and total time in bed**

1. As you can see from the graph above, there is a positive correlation between the total minutes asleep and the amount of time    spent in bed.



2. Using this data, Bellabeat can use an app that notifies its customers about when it would be the right time to go to bed so    that they can get an adequate amount of sleep.

**Hourly Steps**

```
hours = hourly_steps.groupby('hour',sort=False)
â€‹
StepTotal = hours.sum()['StepTotal']
â€‹
hours = [hours for hours, df in hours]
â€‹
plt.bar(hours,StepTotal)
plt.xticks(hours,rotation = 'vertical',size = 10)
plt.xlabel('Hours')
plt.ylabel('Total Steps')
plt.title("Hourly Steps")
plt.show()
```
![image](https://user-images.githubusercontent.com/100290609/217100948-44d9f774-8f26-414d-872d-ff4ca9a4f829.png)

**Analysis**


- From 5PM to 7PM the users take the most steps.

## Phase 6: ACT

**Recommendations for Bellabeat Marketing Strategy:**

- Based on the activity levels and amount of calories burned, users appear to burn more calories with more exercise. Therefore, Bellabeat should encourage users to  exercise more through reminders. They could also offer app incentives, such as give users app credits for every 1000 steps, which can then be used to redeem prizes or vouchers.

- Sedentary make up a significant portion, 81% of users daily active minutes. Users spend on avg 12 hours a day in sedentary minutes, 4 hours lightly active, and only half-hour in fairly+very active!

- We see the most change on Saturday: users take more steps, burn more calories, and spend less time sedentary. Sunday is the most "lazy" day for users.
54% of the users who recorded their sleep data spent 55 minutes awake in bed before falling asleep.

- Users takes the most steps from 5 PM to 7 PM Users who are sedentary take minimal steps and burn 1500 to 2500 calories compared to users who are more active, take more steps, but still burn similar calories.

- The data also shows many people lead either a lightly active or sedentary lifestyle, which may be due to the nature of their work or the lack of time to exercise. Bellabeat could have a section on their app for short workout videos or short exercises (for example, 10 minute videos) that their customers can follow along to if they donâ€™t necessarily want to exercise alone.

- To encourage better sleeping habits, Bellabeat could incorporate reminders through an app that notifies users of the best time to go to sleep and wake up in order to feel refreshed in the morning and get adequate amount of sleep. The app could also automatically turn on â€˜do not disturbâ€™ mode and turn on â€˜night modeâ€™ on the customersâ€™ phones to signal the user that they are not disturbed by messages or phone calls from family and friends.

- The High BMI user's could be given better suggestions and advices on how to reduce and improve their lifestyle

**Recommendations based on the limitations of the dataset:**

- A larger sample size in order to improve the statistical significance of the analysis.

- Collect a longer period of tracking data, ideally for 6 months to a year, to account for behavioural changes due to the changes in seasons.

- The need to obtain current data in order to better reflect current consumer behaviours and/or trends in smart device usage.

- Collect data from internal sources (if possible) and/or from primary/secondary data sources to increase credibility and reliability of the datasets.



